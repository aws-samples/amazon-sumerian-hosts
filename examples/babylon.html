<!-- 
  Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
  SPDX-License-Identifier: MIT-0 
-->
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Babylon.js Host Test</title>
    <style>
      html,
      body {
        overflow: hidden;
        width: 100%;
        height: 100%;
        margin: 0;
        padding: 0;
      }

      #renderCanvas {
        width: 100%;
        height: 100%;
        touch-action: none;
      }

      #textToSpeech {
        position: fixed;
        top: 0;
        left: 0;
        z-index: 2;
        display: none;
      }

      #textEntry {
        min-width: 305px;
        min-height: 200px;
      }

      .button {
        width: 75px;
      }

      #loadScreen {
        display: flex;
        align-items: center;
        justify-content: center;
        width: 100%;
        height: 100%;
        background-image: url('assets/images/load_screen.png');
        background-color: gray;
        background-repeat: no-repeat;
        background-attachment: fixed;
        background-position: center;
        background-size: contain;
        z-index: 9999;
      }

      #loader {
        border: 16px solid #3498db38;
        border-radius: 50%;
        border-top: 16px solid #3498db;
        width: 120px;
        height: 120px;
        -webkit-animation: spin 2s linear infinite;
        animation: spin 2s linear infinite;
        position: fixed;
      }

      @-webkit-keyframes spin {
        0% {
          -webkit-transform: rotate(0deg);
        }
        100% {
          -webkit-transform: rotate(360deg);
        }
      }

      @keyframes spin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }

      @keyframes fadeOutAnimation {
        0% {
          opacity: 1;
        }
        100% {
          opacity: 0;
        }
      }

      @-webkit-keyframes fadeOutAnimation {
        0% {
          opacity: 1;
        }
        100% {
          opacity: 0;
        }
      }
    </style>

    <!--Enable drag and drop text files on text to speech input area-->
    <script src="./scriptDependencies/dragDropTextArea.js"></script>
    <!--Text to speech dependency-->
    <script
      type="text/javascript"
      src="https://sdk.amazonaws.com/js/aws-sdk-2.645.0.min.js"
    ></script>
    <!--Babylon.js dependencies-->
    <script src="./scriptDependencies/babylon.js"></script>
    <script src="./scriptDependencies/babylonjs.loaders.min.js"></script>
    <!--Host build file-->
    <script type="text/javascript" src="../dist/host.babylon.js"></script>
  </head>

  <body>
    <!--Loading screen-->
    <div id="loadScreen">
      <div id="loader"></div>
    </div>

    <!--Text to speech controls-->
    <div id="textToSpeech">
      <div>
        <textarea autofocus size="23" type="text" id="textEntry">
<speak>
  <amazon:domain name="conversational">Hi there, my name is Maya. I used
    to only be a host inside Amazon Sumerian, but now you can use me in other
    Javascript runtime environments like three<sub alias="">.</sub>js and
    Babylon<sub alias="">.</sub>js. Right now I&apos;m in Babylon<sub alias="">.</sub>js.
  </amazon:domain>
</speak>
        </textarea>
      </div>
      <button id="play" class="button">Play</button>
      <button id="pause" class="button">Pause</button>
      <button id="resume" class="button">Resume</button>
      <button id="stop" class="button">Stop</button>
      <div>
        <button id="gestures" class="button">Generate Gestures</button>
      </div>
    </div>

    <!--Create the Babylon.js scene-->
    <script>
      async function main() {
        // Initialize AWS and create Polly service objects
        window.AWS.config.region = 'us-west-2';
        window.AWS.config.credentials = new AWS.CognitoIdentityCredentials({
          IdentityPoolId: '<Enter Cognito Identity Pool ID here>',
        });
        const polly = new AWS.Polly();
        const presigner = new AWS.Polly.Presigner();
        const speechInit = HOST.aws.TextToSpeechFeature.initializeService(
          polly,
          presigner,
          window.AWS.VERSION
        );

        // Define the glTF assets that will represent the host
        const characterFile =
          './assets/glTF/characters/adult_female/maya/maya.gltf';
        const animationPath = './assets/glTF/animations/adult_female';
        const animationFiles = ['stand_idle.glb', 'lipsync.glb', 'gesture.glb'];
        const gestureConfigFile = 'gesture.json';
        const audioAttachJoint = 'char:def_c_neckB'; // Name of the joint to attach audio to
        const voice = 'Joanna'; // Polly voice. Full list of available voices at: https://docs.aws.amazon.com/polly/latest/dg/voicelist.html
        const voiceEngine = 'neural'; // Neural engine is not available for all voices in all regions: https://docs.aws.amazon.com/polly/latest/dg/NTTS-main.html

        // Set up the scene and host
        const scene = createScene();
        const {character, clips, bindPoseOffset} = await loadCharacter(
          scene,
          characterFile,
          animationPath,
          animationFiles
        );

        // Read the gesture config file. This file contains options for splitting up
        // each animation in gestures.glb into 3 sub-animations and initializing them
        // as a QueueState animation.
        const gestureConfig = await fetch(
          `${animationPath}/${gestureConfigFile}`
        ).then(response => response.json());

        const [idleClips, lipsyncClips, gestureClips] = clips;
        const host = createHost(
          character,
          audioAttachJoint,
          voice,
          voiceEngine,
          idleClips[0],
          lipsyncClips,
          gestureClips,
          gestureConfig,
          bindPoseOffset,
          scene
        );

        // Hide the load screen and how the text input
        document.getElementById('textToSpeech').style.display = 'inline-block';
        document.getElementById('loadScreen').style.display = 'none';

        // Wait for the TextToSpeechFeature to be ready
        await speechInit;

        // Enable drag/drop text files on the speech text area
        enableDragDrop('textEntry');

        // Play, pause, resume and stop the contents of the text input as speech
        // when buttons are clicked
        const speechInput = document.getElementById('textEntry');
        ['play', 'pause', 'resume', 'stop'].forEach(id => {
          const button = document.getElementById(id);
          button.onclick = () => {
            host.TextToSpeechFeature[id](speechInput.value);
          };
        });

        // Update the text area text with gesture SSML markup when clicked
        const gestureButton = document.getElementById('gestures');
        const gestureMap = host.GestureFeature.createGestureMap();
        gestureButton.onclick = () => {
          speechInput.value = HOST.aws.TextToSpeechUtils.autoGenerateSSMLMarks(
            speechInput.value,
            gestureMap
          );
        };

        // Set up base scene
        function createScene() {
          // Canvas
          const canvas = document.createElement('canvas');
          canvas.id = 'renderCanvas';
          canvas.style.width = `${window.innerWidth}px`;
          canvas.style.height = `${window.innerHeight}px`;
          document.body.appendChild(canvas);

          // Scene
          const engine = new BABYLON.Engine(canvas, true, undefined, true);
          const scene = new BABYLON.Scene(engine);
          scene.useRightHandedSystem = true;
          scene.fogColor.set(0.5, 0.5, 0.5);
          const assetManager = new BABYLON.AssetsManager(scene);

          // Use our own button to enable audio
          BABYLON.Engine.audioEngine.useCustomUnlockedButton = true;

          // Handle window resize
          window.addEventListener('resize', function() {
            canvas.style.width = `${window.innerWidth}px`;
            canvas.style.height = `${window.innerHeight}px`;
            engine.resize();
          });
          engine.runRenderLoop(scene.render.bind(scene));

          // Camera
          const camera = new BABYLON.ArcRotateCamera(
            'Camera',
            Math.PI / 2,
            Math.PI / 2,
            1.6,
            new BABYLON.Vector3(0, 1.6, 0),
            scene
          );
          camera.minZ = 0.1;
          camera.maxZ = 1000;
          camera.setPosition(new BABYLON.Vector3(0, 1.6, 2.6));
          camera.setTarget(new BABYLON.Vector3(0, 1, 0));
          camera.wheelDeltaPercentage = 0.01;
          camera.attachControl(canvas, true);

          // Lights
          var hemiLight = new BABYLON.HemisphericLight(
            'light1',
            new BABYLON.Vector3(0, 1, 0),
            scene
          );
          hemiLight.intensity = 0.6;
          hemiLight.specular = BABYLON.Color3.Black();

          var dirLight = new BABYLON.DirectionalLight(
            'dir01',
            new BABYLON.Vector3(0, -0.5, -1.0),
            scene
          );
          dirLight.position = new BABYLON.Vector3(0, 5, 5);

          // Shadows
          shadowGenerator = new BABYLON.ShadowGenerator(1024, dirLight);
          shadowGenerator.useBlurExponentialShadowMap = true;
          shadowGenerator.blurKernel = 32;

          // Environment
          var helper = scene.createDefaultEnvironment({
            enableGroundShadow: true,
          });
          helper.groundMaterial.primaryColor.set(0.5, 0.5, 0.5);
          helper.ground.receiveShadows = true;

          return scene;
        }

        // Load character model and animations
        async function loadCharacter(
          scene,
          characterFile,
          animationPath,
          animationFiles
        ) {
          // Load character model
          const {
            character,
            bindPoseOffset,
          } = await BABYLON.SceneLoader.LoadAssetContainerAsync(
            characterFile
          ).then(container => {
            const [character] = container.meshes;
            const [bindPoseOffset] = container.animationGroups;

            // Make the offset pose additive
            if (bindPoseOffset) {
              BABYLON.AnimationGroup.MakeAnimationAdditive(bindPoseOffset);
            }

            // Add everything to the scene
            container.scene = scene;
            container.addAllToScene();

            // Cast shadows but don't receive
            shadowGenerator.addShadowCaster(character, true);
            for (var index = 0; index < container.meshes.length; index++) {
              container.meshes[index].receiveShadows = false;
            }

            return {character, bindPoseOffset};
          });

          // Load animations
          const clips = await Promise.all(
            animationFiles.map((filename, index) => {
              const filePath = `${animationPath}/${filename}`;

              return BABYLON.SceneLoader.LoadAssetContainerAsync(filePath).then(
                container => {
                  const startingIndex = scene.animatables.length;
                  const firstIndex = scene.animationGroups.length;

                  // Apply animation to character
                  container.mergeAnimationsTo(
                    scene,
                    scene.animatables.slice(startingIndex),
                    target => scene.getNodeByName(target.name)
                  );

                  // Find the new animations and destroy the container
                  const animations = scene.animationGroups.slice(firstIndex);
                  container.dispose();
                  scene.onAnimationFileImportedObservable.notifyObservers(
                    scene
                  );

                  return animations.map((group, i) => {
                    // Make the lipsync animation additive
                    if (index) {
                      BABYLON.AnimationGroup.MakeAnimationAdditive(group);
                    }

                    return group;
                  });
                }
              );
            })
          );

          return {character, clips, bindPoseOffset};
        }

        // Initialize the host
        function createHost(
          character,
          audioAttachJoint,
          voice,
          engine,
          idleClip,
          lipsyncClips,
          gestureClips,
          gestureConfig,
          bindPoseOffset,
          scene
        ) {
          // Add the host to the render loop
          const host = new HOST.HostObject({owner: character});
          scene.onBeforeRenderObservable.add(() => {
            host.update();
          });

          // Set up text to speech
          const [audioAttach] = character.getDescendants(
            false,
            node => node.name === audioAttachJoint
          );
          host.addFeature(HOST.aws.TextToSpeechFeature, false, {
            scene,
            attachTo: audioAttach,
            voice,
            engine,
          });

          // Set up animation
          host.addFeature(HOST.anim.AnimationFeature);

          // Base idle
          host.AnimationFeature.addLayer('Base');
          host.AnimationFeature.addAnimation(
            'Base',
            idleClip.name,
            HOST.anim.AnimationTypes.single,
            {clip: idleClip}
          );
          host.AnimationFeature.playAnimation('Base', idleClip.name);

          // Talking idle
          host.AnimationFeature.addLayer('Talk', {
            transitionTime: 0.75,
            blendMode: HOST.anim.LayerBlendModes.Additive,
          });
          host.AnimationFeature.setLayerWeight('Talk', 0);
          const talkClip = lipsyncClips.find(c => c.name === 'stand_talk');
          lipsyncClips.splice(lipsyncClips.indexOf(talkClip), 1);
          host.AnimationFeature.addAnimation(
            'Talk',
            talkClip.name,
            HOST.anim.AnimationTypes.single,
            {clip: talkClip}
          );
          host.AnimationFeature.playAnimation('Talk', talkClip.name);

          // Viseme poses
          host.AnimationFeature.addLayer('Viseme', {
            transitionTime: 0.12,
            blendMode: HOST.anim.LayerBlendModes.Additive,
          });
          host.AnimationFeature.setLayerWeight('Viseme', 0);
          const blendStateOptions = lipsyncClips.map(clip => {
            return {
              name: clip.name,
              clip,
              weight: 0,
              from: 1 / 30,
              to: 2 / 30,
            };
          });
          host.AnimationFeature.addAnimation(
            'Viseme',
            'visemes',
            HOST.anim.AnimationTypes.freeBlend,
            {blendStateOptions}
          );
          host.AnimationFeature.playAnimation('Viseme', 'visemes');

          // Gesture animations
          host.AnimationFeature.addLayer('Gesture', {
            transitionTime: 0.5,
            blendMode: HOST.anim.LayerBlendModes.Additive,
          });

          gestureClips.forEach(clip => {
            const {name} = clip;
            const config = gestureConfig[name];

            if (config !== undefined) {
              // Add the clip to each queueOption so it can be split up
              config.queueOptions.forEach((option, index) => {
                option.clip = clip;
                option.to /= 30.0;
                option.from /= 30.0;
              });
              host.AnimationFeature.addAnimation(
                'Gesture',
                name,
                HOST.anim.AnimationTypes.queue,
                config
              );
            } else {
              host.AnimationFeature.addAnimation(
                'Gesture',
                name,
                HOST.anim.AnimationTypes.single,
                {clip}
              );
            }
          });

          // Apply bindPoseOffset clip if it exists
          if (bindPoseOffset !== undefined) {
            host.AnimationFeature.addLayer('BindPoseOffset', {
              blendMode: HOST.anim.LayerBlendModes.Additive,
            });
            host.AnimationFeature.addAnimation(
              'BindPoseOffset',
              bindPoseOffset.name,
              HOST.anim.AnimationTypes.single,
              {clip: bindPoseOffset, from: 1 / 30, to: 2 / 30}
            );
            host.AnimationFeature.playAnimation(
              'BindPoseOffset',
              bindPoseOffset.name
            );
          }

          // Set up Lipsync
          const visemeOptions = {
            layers: [
              {
                name: 'Viseme',
                animation: 'visemes',
              },
            ],
          };
          const talkingOptions = {
            layers: [{name: 'Talk', animation: 'stand_talk'}],
          };
          host.addFeature(
            HOST.LipsyncFeature,
            false,
            visemeOptions,
            talkingOptions
          );

          // Set up Gestures
          host.addFeature(HOST.GestureFeature, false, {
            layers: {Gesture: {minimumInterval: 3}},
          });

          return host;
        }
      }

      main();
    </script>
  </body>
</html>
